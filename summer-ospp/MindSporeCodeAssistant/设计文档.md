## **知识库设计：**

收集并整理MindSpore的官方文档、API参考资料、精选教程等，建立一个全面且多层次的知识库作为信息基础。

### 1. 概述

Mindspore 作为一款全场景深度学习框架，其官方文档是开发者学习和使用的核心资源。该文档库规模庞大、内容多样，涵盖了从入门教程、API 详情到设计原理和最佳实践等各个方面。为了提升开发者的查询效率和问题解决能力，本项目旨在设计并实现一个基于检索增强生成（Retrieval-Augmented Generation, RAG）技术的智能问答系统。

#### 1.2. 面临的挑战

- **知识异构性**：文档内容形式多样，包括结构化的 API 文档、长篇的设计原理、步骤化的教程以及零散的 FAQ，单一处理策略难以适用。
- **知识关联性**：文档内容并非孤立，API、教程和设计文档之间存在紧密的逻辑关联，简单的文本检索会丢失这种深层联系。
- **代码与文本混合**：文档中含有大量代码示例和 API 签名，需要模型同时具备强大的代码理解和自然语言理解能力。
- **查询意图复杂**：用户问题覆盖 API 查询、操作方法、概念理解、故障排查和代码生成等多种意图，对系统的查询理解能力要求极高。

### 2. 系统整体架构

本 RAG 系统设计遵循“离线索引”与“在线检索生成”分离的经典模式，以确保在线服务的低延迟和高效率。

- **离线索引管道 (Offline Indexing Pipeline)** ：负责对原始的 Mindspore 文档库进行预处理，包括解析、分块、元数据提取和建立可供快速检索的索引。此过程定期执行，以同步文档的更新。
- **在线检索与生成管道 (Online Retrieval &amp; Generation Pipeline)** ：负责实时处理用户查询。它接收用户输入，通过一系列检索、排序和生成步骤，最终输出答案。

### 3. 离线索引管道（Offline Indexing Pipeline）详细设计

此阶段的核心任务是将非结构化和半结构化的文档转化为结构化的、可检索的知识单元（Chunks）。

#### 3.1. 模块一：智能文档解析与分块 (Intelligent Parsing & Chunking)

针对不同类型的文档采用定制化的分块策略，以最大化保留其语义完整性。

- **API 文档 (** **`/api`** **)**

  - **策略**：**结构化解析（Structural Parsing）** 。放弃基于长度的文本切割，将每个 API 的 Markdown 文件视为一个完整的、不可分割的知识单元。
  - **实现**：开发一个专门的 Markdown 解析器，从每个 API 文件中抽取出以下关键字段，并组织成一个 JSON 对象：

    - `api_signature`: 完整的 API 签名，如 `mindspore.nn.Conv2d(in_channels, out_channels, kernel_size, ...)`。
    - `description`: API 的功能描述。
    - `parameters`: 一个包含`{name, type, description}`的对象列表，用于描述每个参数。
    - `returns`: 返回值的描述。
    - `code_examples`: 完整保留所有代码示例块。
    - `notes`: 注意事项或警告。
  - **优势**：完整保留了 API 的所有信息，便于针对参数、用法或代码示例的精确查询。
- **教程与设计文档 (** **`/tutorials`** **,**   **`/design`** **)**

  - **策略**：**基于标题的语义分块（Semantic Chunking）** 。
  - **实现**：利用 Markdown 的层级结构，沿二级 (`##`) 或三级 (`###`) 标题进行文档分割。每个生成的块（Chunk）都应包含其上游所有层级的标题作为前缀，以保留其在文档中的完整上下文。
  - **示例**：`tutorials/parallel/pipeline_parallel.md` 文件中的 "## 流水线并行原理" 章节将被切分为一个独立的 Chunk，其内容包含该标题及该标题下的所有文本和代码。
- **FAQ 文档 (** **`/faq`** **)**

  - **策略**：**问答对（Q&amp;A Pair）分块**。
  - **实现**：解析 FAQ 文件，将每一个问题（Question）及其对应的完整答案（Answer）合并成一个独立的 Chunk。

#### 3.2. 模块二：元数据提取 (Metadata Extraction)

为每个 Chunk 附加丰富的元数据，是实现高级检索和过滤的关键。

- **提取内容**：

  - `source`: 文档的源文件路径，如 `/api/mindspore/Tensor/mindspore.Tensor.add.md`。
  - `url`: 指向该知识在官方网站上对应的 URL，方便用户溯源。
  - `category`: 文档的一级分类，如 `api`, `tutorial`, `faq`, `design`。
  - `subcategory`: 文档的二级分类，如 `Tensor`, `parallel`, `installation`。
  - `title`: Chunk 所属的标题或 API 的名称。
  - `version`: 文档对应的 Mindspore 版本号。

#### 3.3. 模块三：嵌入与混合索引 (Embedding & Hybrid Indexing)

为了兼顾语义相似性与关键词精确性，我们采用混合搜索策略。

- **嵌入模型 (Embedding Model)** ：

  - **选型**：推荐使用在代码和中英双语技术语料上表现优异的模型，如 **BGE-M3**。这些模型能更好地捕捉代码片段和技术术语的语义。
- **索引构建**：

  1. **向量索引 (Vector Index)** ：将每个 Chunk 的内容通过嵌入模型转换为高维向量，存入向量数据库。
  2. **关键词索引 (Keyword Index)** ：同时，为每个 Chunk 的文本内容（尤其是 API 名称、参数名、标题等）建立一个传统的 BM25/TF-IDF 倒排索引。

### 4. 在线检索与生成管道（Online Retrieval & Generation Pipeline）详细设计

此阶段负责在用户发出请求时，实时地完成从查询到生成答案的全过程。

#### 4.1. 模块一：查询理解与转换 (Query Understanding & Transformation)

将用户的自然语言查询转化为机器更容易处理的结构化指令。

- **实现**：通过一个轻量级 LLM或基于规则的系统执行以下任务：

  1. **意图识别**：将查询分类为 `API查找`、`操作方法(How-to)`、`概念解释`、`代码示例`、`故障排查` 等。
  2. **实体提取**：抽取出查询中的核心实体，如 `mindspore.ops.Add`、`Adam`、`pipeline parallel` 等。
  3. **查询重写 (Query Rewriting)** ：

      - **HyDE (Hypothetical Document Embeddings)** ：对于概念性或方法性问题（如 "如何提升模型训练速度？"），先让 LLM 生成一个假想的、理想的答案文档，再用这个假想文档的向量去检索，能更精准地匹配到解决方案类的文档。
      - **子查询生成**：对于复杂问题（如 "Mindspore 的流水线并行和张量并行有什么区别？"），将其分解为多个子查询（"Mindspore 流水线并行"、"Mindspore 张量并行"），分别检索后再综合。

#### 4.2. 模块二：多路召回与融合 (Multi-path Retrieval & Fusion)

从索引库中全面、高效地召回所有潜在相关的候选 Chunks。

1. **并行检索**：

    - **向量检索**：使用转换后的查询向量，在向量索引中检索 Top-K（如 K\=50）个最相似的 Chunks。
    - **关键词检索**：使用提取出的实体，在关键词索引中进行 BM25 搜索，同样召回 Top-K 个 Chunks。
    - **元数据过滤**：利用查询中提取的实体或意图，对检索进行预过滤。例如，如果识别到 API 名称，可将搜索范围限定在 `category: 'api'` 内。
2. **结果融合**：

    - **算法**：采用 **倒数排序融合 (Reciprocal Rank Fusion, RRF)**  算法。RRF 算法不依赖于原始的相关性分数，只根据候选者在不同列表中的排名位置进行融合，效果鲁棒且易于实现。
    - **输出**：融合后得到一个更加可靠的候选列表，取前 20-30 个 Chunks 进入下一阶段。

#### 4.3. 模块三：精排 (Reranking)

对召回的候选列表进行二次排序，筛选出与查询最相关的黄金上下文。

- **流程**：将用户的**原始查询**与每个候选 Chunk 拼接成对（`[CLS] query [SEP] chunk_text [SEP]`），输入到 Cross-Encoder 模型中，模型会输出一个精确的相关性分数（0到1之间）。
- **输出**：根据 Rerank模型的分数对候选列表重新排序，选取 Top-N（如 N\=3-5）个最相关的 Chunks 作为最终提供给生成模型的上下文。

#### 4.4. 模块四：上下文增强与答案生成 (Context Augmentation & Generation)

利用精排后的高质量上下文，生成最终的答案。

1. **Prompt 工程 (Prompt Engineering)** ：

    - 设计一个结构化的 Prompt 模板，明确地指示 LLM 的角色、任务、约束和信息来源。

    ```
    # 指令

    你是一位资深的 MindSpore 技术支持专家。你的任务是基于下面提供的“上下文信息”，用清晰、准确、专业的中文回答用户的“问题”。

    # 约束
    - **严格基于上下文**：你的回答必须完全依据所提供的上下文信息，禁止利用你的内部知识进行任何补充或猜测。
    - **未知则答“未知”**：如果上下文中没有足够的信息来回答问题，你必须直接回复：“根据我所掌握的资料，无法回答您的问题。”
    - **引用来源**：在回答中，每当你引用了某段上下文的信息，必须在句末以 "[来源: URL或文件路径]" 的格式注明出处。如果一个答案综合了多个来源，需全部列出。
    - **保持专业**：语言风格应专业、简洁。

    # 上下文信息
    ---
    [上下文 1]
    来源: {source_url_1}
    内容: {chunk_content_1}
    ---
    [上下文 2]
    来源: {source_url_2}
    内容: {chunk_content_2}
    ---
    ...

    # 问题
    {user_query}

    # 回答
    ```
2. **生成模型 (Generator LLM)** ：

    - **选型**：推荐使用能力强大的生成模型，以确保其能很好地遵循指令、进行逻辑推理并生成高质量的文本。
    - **输出**：模型根据构建好的 Prompt 生成最终答案，该答案将是可靠、有据可查且格式规范的。

## **Workflow 详解**

### **昇思知识库-报错地图版 Workflow 详解**

#### **1. 概述**

与通用的知识库问答机器人不同，该版本特别优化了处理**报错日志**的场景。它通过一个精心设计的 RAG（检索增强生成）工作流，能够智能分析用户输入的报错信息，精确检索相关的知识，并生成结构化、专业化的解决方案，旨在为开发者提供一个快速定位并解决问题的“报错地图”。

#### **2. 核心工作流程**

该应用的工作流是一个典型的 RAG 流程，但针对报错场景进行了深度定制。其核心逻辑可以概括为以下几个步骤：

1. **查询预处理**：接收用户输入，并利用大语言模型（LLM）进行智能分析和改写，将其转化为最适合知识库检索的查询语句。
2. **分路并行检索**：将优化后的查询同时发送到两个独立的知识库（API 库与非 API 库）进行检索，以最大化召回率。
3. **结果合并**：通过一个代码节点，将两路检索结果进行合并处理。
4. **答案生成**：将合并后的知识上下文喂给专门负责生成答案的 LLM，该模型被严格设定为 MindSpore 技术专家的角色，依据指令生成最终答案。
5. **历史记录管理**：在流程的开始和结束阶段，将用户问题和模型答案追加到对话历史中，以支持多轮对话。

#### **3. 时序图与流程详解**

下面是整个工作流程的交互时序图，直观地展示了从用户输入到系统回复的全过程。

![昇思知识库-报错地图版-whole-workflow 1](https://image-hosting-service.obs.cn-north-4.myhuaweicloud.com/202510271559436.svg)

![mermaid-1759047754405](https://image-hosting-service.obs.cn-north-4.myhuaweicloud.com/202510271559206.svg)

好的，遵照您的要求，这里是更新后的 `节点功能详解` 部分，其中包含了关键 LLM 节点的完整提示词（Prompt）。

---

#### **4. 节点功能详解**

以下是对每个关键节点的详细功能解释，与时序图中的步骤一一对应。

**步骤 1：启动与历史记录（****`Start`** **,**  **`Assign1`** **）**

- **`Start`** **（开始）** : 接收用户的输入，作为整个工作流的起点。
- **`Assign1`** **（变量赋值 1）** : 紧接着开始节点，此节点立即将用户当前的输入（`sys.query`）追加到名为 `Conversation_History` 的全局变量中。这一步确保了即使后续流程失败，用户的原始问题也已被记录，为多轮对话提供上下文基础。

**步骤 2：查询预处理（****`Rewrite`**  **- 对话重写）**

- **节点类型**: LLM
- **核心功能**: 这是整个流程的“智能大脑”，专门负责**查询优化**。它接收用户输入和对话历史，并被赋予了一个特殊的角色：“专为 MindSpore 报错诊断场景设计的 AI 查询优化专家”。
- **智能决策**: 该模型的 Prompt 指示它执行一个关键的二元判断：

  - **如果输入是【报错日志】** : 它会忽略历史对话，直接从日志中提取核心错误信息（如 `BrokenPipeError`）和相关的技术实体（如 `enable_compile_cache`），组合成一行由空格分隔的关键词，如 `MindSpore BrokenPipeError: [Errno 32] Broken pipe enable_compile_cache`。这极大地提升了关键词检索的精确度。
  - **如果输入是【追问短句】** （如“为什么”）：它会结合上一轮对话的主题（如 `BrokenPipeError`），将问题改写成一个完整的、独立的查询，如 `MindSpore enable_compile_cache 导致 BrokenPipeError 的原因`。
- **输出**: 无论采用哪种策略，此节点最终只输出一行**高度优化、利于检索**的查询语句。
- **提示词（Prompt）展示**:

  ```
  **System Prompt:**

  ‍```
  # 角色
  你是一个专为 MindSpore 报错诊断场景设计的【AI查询优化专家】。

  # 核心任务
  你的唯一任务是：智能分析【用户当前消息】的类型，并结合【历史对话记录】，生成一句最适合在知识库中进行检索的、独立完整的查询语句。

  # 思考与执行步骤
  1.  **分析当前输入**: 判断【当前用户消息】是“报错日志”还是“追问短句”？
      *   **报错日志**: 通常是多行的、包含代码路径和 `Error`, `Exception` 等关键词的文本。
      *   **追问短句**: 通常是简短的自然语言问题，如“为什么”、“详细说下”、“还有别的方法吗”。

  2.  **根据类型选择策略**:
      *   **情况 A：如果输入是【报错日志】 -> 执行【关键词提取】**
          a.  **忽略历史对话**，完全聚焦于当前这条日志。
          b.  **定位核心错误**: 找到 `XxxError: [message]` 这样的标志性错误行。
          c.  **提取技术实体**: 从日志中找出与MindSpore相关的API、算子或参数，如 `enable_compile_cache`。
          d.  **组合查询**: 将错误与技术实体组合成一行由空格分隔的关键词。

      *   **情况 B：如果输入是【追问短句】 -> 执行【对话改写】**
          a.  **分析追问意图**: 理解当前短句的核心意图（是问原因？要更多细节？还是其他方案？）。
          b.  **回顾历史上下文**: 查看【历史消息对话记录】，找到上一轮对话的核心主题（比如是哪个具体的报错，哪个解决方案）。
          c.  **融合生成新查询**: 将“追问意图”和“历史主题”结合，生成一个完整、无需依赖上下文就能被理解的新查询。

  # 输出准则 (必须遵守)
  *   **错误信息原文保留**: 提取日志时，`Error` 的原文必须保持不变。
  *   **去芜存菁**: 无论是提取还是改写，都要删除无关的客套话、路径和行号。
  *   **输出纯净**: 最终只输出一行改写/提取后的查询语句，不含任何解释。

  # 示例
  ---
  **【场景1: 首次输入是日志】**
  *   历史消息: `[]`
  *   当前用户消息: `(一个包含 BrokenPipeError 和 enable_compile_cache 的长日志)`
  *   **你的决策 -> 情况 A: 关键词提取**
  *   **输出**: `MindSpore BrokenPipeError: [Errno 32] Broken pipe enable_compile_cache`
  ---
  **【场景2: 用户在得到答案后追问原因】**
  *   历史消息: `用户: (日志...)`, `机器人: ...该问题是由于开启编译缓存，但写入路径不存在导致。解决方案是删除 enable_compile_cache...`
  *   当前用户消息: `为什么会这样？`
  *   **你的决策 -> 情况 B: 对话改写**
  *   **输出**: `MindSpore enable_compile_cache 导致 BrokenPipeError 的原因`
  ---

  # 你的任务
  请处理以下输入。
  ‍```

  **User Prompt:**

  ‍```
  历史消息对话记录：【{{#conversation.Conversation_History#}}】
  当前用户消息：{{#sys.query#}}
  ‍```
  ```

**步骤 3：分路并行检索（****`RetrieverAPI`** **,**  **`RetrieverNonAPI`** **）**

- **节点类型**: Knowledge Retrieval
- **核心功能**: 工作流将上一步优化后的查询词，**同时**发送给两个独立的知识检索节点。
- **`RetrieverAPI`**  **(知识检索 - API)** :

  - **知识库**: 专门索引 MindSpore API 相关文档的知识库。
  - **检索配置**: 设置了极高的关键词权重（`keyword_weight: 0.9`）和较低的向量权重（`vector_weight: 0.1`）。这种配置是为了**优先精确匹配** API 名称、参数等专有名词。
- **`RetrieverNonAPI`**  **(知识检索 - 除 API)** :

  - **知识库**: 包含 MindSpore 教程、FAQ、社区问题等非 API 文档。
  - **检索配置**: 同样采用了 `0.9` 的关键词权重，以确保在处理报错日志时，能优先匹配到错误码等关键文本。
- **设计目的**: 这种分路设计+高关键词权重的策略，是“报错地图版”的核心优化点，确保了在处理包含大量精确技术术语的报错信息时，能够最大程度地召回最相关的文档。每个检索器被配置为返回最相关的 Top 5 个结果。

**步骤 4：结果合并（****`Merger`**  **- 代码执行）**

- **节点类型**: Code
- **核心功能**: 这是一个简单的 Python 代码节点，用于将上一步两路检索返回的结果列表进行合并。
- **执行逻辑**: 脚本将 `RetrieverAPI` 的结果列表与 `RetrieverNonAPI` 的结果列表简单地拼接在一起，形成一个包含最多 10 个知识片段的统一上下文列表，然后传递给下一步。

**步骤 5：答案生成（****`Generator`**  **- 回答生成）**

- **节点类型**: LLM
- **核心功能**: 这是负责生成最终答案的 LLM 节点。它接收合并后的知识库上下文作为核心信息源。
- **关键指令 (Prompt)** : 此节点的 Prompt 对其输出格式和内容有极其严格的要求：

  - **角色扮演**: 扮演“顶级的 MindSpore 技术专家”。
  - **信息来源**: 严格基于提供的知识库内容回答，禁止自由发挥或提及“根据知识库”等词语。
  - **结构化输出**: 回答必须包含清晰的  **“问题分析”**  和  **“解决方案”**  两部分。
  - **附带环境信息**: **必须**在回答的末尾，从知识库内容中提取并附上该解决方案对应的环境信息（系统、硬件、MindSpore 版本等），格式严格固定。
- **输出**: 一个专业、结构化、包含解决方案和复现环境的完整回答。
- **提示词（Prompt）展示**:

  ```
  ======================= 知识库内容 =======================
  {{#context#}}

  ======================= 用户输入（已根据上下文改写） =======================
  用户原始query：
  {{#sys.query#}}
  你是一个顶级的 MindSpore 技术专家，你的核心任务是基于上方提供的知识库内容，尽最大努力为用户生成精准、纯粹的技术答案。

  【核心回答原则】
  *   **知识库是第一信息源**：你的回答必须绝对优先、并尽可能全面地基于上方提供的“知识库内容”。
  *   **谨慎补充自有知识**：仅当知识库内容不足以回答问题时，才可动用你自身的 MindSpore 知识储备进行补充。

  【QA 绝对优先】
  *   如果知识库中存在**直接回答用户问题的标准答案**（如FAQ），则**必须且只能**输出该答案原文，严禁任何形式的改写或融合。

  【代码处理规则】
  *   若知识库中包含代码示例，**必须完全按原文输出**，不得修改、简化或扩展。
  *   若知识库中无相关代码，可以提供基于 MindSpore 通用实践回答。

  【回答风格与结构】
  *   语言为中文，语气专业客观，结构清晰，可分点阐述。
  *   回答结构应包含清晰的**问题分析**和**解决方案**。
  *   重点关注对象/模块/API名称、关键参数、错误码、版本/设备/后端（Ascend/GPU/CPU）、训练/推理场景等技术细节。
  **必须**在回答的末尾附上从知识库中提取的**环境信息**。**若知识库未提供，则不包含此部分内容。**  格式严格如下：
  *   **系统环境**: [例如: EulerOS 2.8]
  *   **硬件环境(Ascend/GPU/CPU)** : [例如: Ascend]
  *   **MindSpore版本**: [例如: 2.2.0]
  *   **执行模式（PyNative/ Graph）** : [例如: Graph, 或“不限”]

  【绝对禁止项】

  - **绝对禁止**在回答中以任何形式提及或暗示答案的信息来源。例如，不得出现“根据知识库”、“文档显示”、“基于通用知识”等词语。
  - **绝对禁止**建议用户查阅官方文档或任何外部链接。
  - **绝对禁止**出现任何内部流程用语，如“经过检索”、“我选择”、“模型评估”等。用户只应看到直接的技术答案。

  【回答生成策略】
  你必须按以下优先级顺序来决定如何回答：

  1. **基于知识库回答**：如果知识库内容**直接且充分**地回答了用户问题，请严格依据知识库内容进行回答。
  2. **补充知识库回答**：如果知识库内容相关但**不完整**，请在知识库内容的基础上，结合你自身的MindSpore知识进行补充，形成一个全面的答案。
  3. **基于自身知识回答**：如果知识库内容**完全不相关或缺失**，你**必须**利用自己全部的MindSpore知识储备，尽力提供一个最可能正确和有用的答案。**即使没有外部知识，也绝不放弃回答。**
  ```

**步骤 6：历史更新与输出（****`Assign2`** **,**  **`Answer`** **）**

- **`Assign2`** **（变量赋值 2）** : 在生成最终答案后，此节点将模型的回答文本追加到 `Conversation_History` 变量中，完成了本次对话的完整记录。
- **`Answer`** **（结束）** : 将 `Generator` 节点生成的最终回答文本呈现给用户，结束本次工作流。

### 昇思知识库文档 Workflow 详细解析

#### **1. 概述**

相较于“报错地图版”，此版本是一个功能更全面、技术更前沿的 **通用型 MindSpore 智能知识库助手**。

此工作流代表了 RAG（检索增强生成）技术的一次显著升级。它不仅包含了多轮对话、分库检索等基础功能，还创新性地引入了 **HyDE（Hypothetical Document Embeddings）**  和 **结果评分重排序** 两大核心技术，旨在全面提升对各类自然语言问题的理解和回答质量，为用户提供更精准、更深入的技术支持。

#### **2. 核心工作流程**

该应用的工作流整合了多种先进的 RAG 策略，其核心逻辑可以概括为以下几个步骤：

1. **查询改写 (Query Rewriting)** : 接收用户输入，利用 LLM 将其改写成一个独立的、包含完整上下文的标准化查询语句。
2. **假设性文档生成 (HyDE)** : 并行地，另一个 LLM 会针对改写后的查询，生成一个“假设性的”完美答案。
3. **双引擎并行检索**: 系统使用两种不同的策略同时进行检索：

    - **语义优先路径**: 使用 HyDE 生成的“假想答案”在 API 知识库中进行向量检索。
    - **混合检索路径**: 使用改写后的“标准查询”在非 API 知识库中进行关键词与向量的混合检索。
4. **智能合并与重排序**: 通过一个代码节点，将两路检索结果合并，并根据各自的 `score`（分数）进行全局降序排序，确保最相关的知识片段排在最前。
5. **答案生成**: 将排序后的高质量知识上下文喂给最终的生成模型，依据指令生成流畅、准确的回答。
6. **历史记录管理**: 在流程的始末，将用户问题和模型答案存入历史记录，以支持连续对话。

#### **3. 时序图与流程详解**

![mermaid-1759048305454](https://image-hosting-service.obs.cn-north-4.myhuaweicloud.com/202510271600579.svg)

![昇思知识库 2.6 返回完整链路-whole-workflow 2](https://image-hosting-service.obs.cn-north-4.myhuaweicloud.com/202510271601876.svg)

#### **4. 节点功能详解**

以下是对 每个关键节点的详细功能解释，与时序图中的步骤一一对应。

**步骤 1：启动与历史记录（****`Start`** **,**  **`Assign1`** **）**

- **`Start`** **（开始）** : 接收用户的输入，作为整个工作流的起点。
- **`Assign1`** **（变量赋值）** : 立即将用户的当前输入（`sys.query`）追加到名为 `conversation_history` 的全局变量中，为多轮对话提供上下文基础。

**步骤 2：查询改写（****`Rewrite`**  **- 对话重写）**

- **节点类型**: LLM
- **核心功能**: 作为流程的第一个智能处理单元，此节点专注于**提升查询质量**。它接收用户输入和对话历史，将口语化、有歧义或依赖上下文的问句（如“它有什么用”）改写成一句独立的、包含所有必要技术关键词的“完美问题”（如“MindSpore Conv2d算子的作用和用法”）。
- **输出**: 一个优化过的、高度利于知识库检索的中文查询语句。
- **提示词（Prompt）展示**:

```
**System Prompt:**

角色

你是一个专为 MindSpore 知识库设计的 AI 查询优化专家。

核心任务

你的唯一任务是：分析用户当前问题和历史对话，将其改写成一句【独立、完整、包含所有必要技术关键词、且高度利于知识库检索】的中文查询语句。

思考步骤 (Chain-of-Thought)

1. **识别核心意图**: 首先，分析【当前用户消息】，明确用户想要了解的核心技术点是什么（例如某个API、某个概念、某个错误）。
2. **扫描历史上下文**: 其次，回顾【历史消息对话记录】，从中提取与核心意图相关的、但当前消息中缺失的关键信息，如：MindSpore框架名、具体API/算子名称、版本号、硬件环境（Ascend/GPU/CPU）、报错信息等。
3. **综合生成新查询**: 最后，将核心意图与补充的上下文信息结合，遵循以下准则，生成一句最终的查询语句。

改写准则 (必须遵守)

... (此处省略与“报错地图版”相同的详细规则) ...

输出格式

【严格要求】: 仅输出改写后的一句中文查询，不要包含任何解释、标签、前缀或多余的文字。

**User Prompt:**

输入

历史消息对话记录：【{{#conversation.conversation_history#}}】

当前对话轮数：{{#sys.dialogue_count#}}

当前用户消息：{{#sys.query#}}
```

**步骤 3：假设性文档生成（****`HyDE`** **）**

- **节点类型**: LLM
- **核心功能**: 这是版本 2.7 的核心创新之一。此节点扮演一个“假想文档生成器”，它接收上一步改写后的“完美问题”，并**生成一个理想中应该存在的、能够完美回答该问题的答案文本**。
- **设计目的**: 这个生成的“假想答案”在语义上与真正相关的知识库文档高度相似。使用它来进行向量检索，可以有效解决“语义鸿沟”问题（即问题和答案的措辞不同但意思相同），从而大幅提升检索的准确率。
- **提示词（Prompt）展示**:

```
**User Prompt:**

你是在MindSpore RAG流程中HyDE的假想文档生成器。为下面的问题生成一个假想性的答案。这个答案应当是详尽、清晰的，它将被用在一个专业知识库中搜索相关信息的查询依据。

问题：{{#1755605354684.text#}}

你的回复应当包含问题（不要修改）和你的回答。

示例：
输入：MindSpore add算子的使用方法和API说明
输出：问题：MindSpore add算子的使用方法和API说明
回答：add 算子是 MindSpore 中最基本、最常用的算子之一，用于对两个输入的 Tensor 进行逐元素的加法运算。
```

**步骤 4：双引擎并行检索（****`RetrieverAPI`** **,**  **`RetrieverNonAPI`** **）**

- **`RetrieverAPI`**  **(知识检索 - API)** :

  - **输入**: 接收 `HyDE` 节点生成的“假想答案”。
  - **策略**: 利用这个富含语义的假想答案，在 API 知识库中进行检索。这是一种纯粹的**语义优先**检索路径。
- **`RetrieverNonAPI`**  **(知识检索 - 除 API)** :

  - **输入**: 接收 `Rewrite` 节点生成的“标准问题”。
  - **策略**: 采用**混合检索**模式（`keyword_weight: 0.3`, `vector_weight: 0.7`），平衡了关键词精确匹配和语义相似性。更重要的是，此节点开启了 `reranking_enable: true`，会在召回后使用 Rerank 模型对结果进行二次精排。
- **设计目的**: 这种双引擎、非对称的检索策略，结合了 HyDE 语义检索和传统混合检索+精排的优点，实现了对不同类型知识的“因材施教”，最大化了召回的广度和精度。

**步骤 5：智能合并与重排序（****`Sorter`**  **- 代码执行）**

- **节点类型**: Code
- **核心功能**: 此代码节点是保证最终答案质量的关键一环，它执行了比简单合并更复杂的操作。
- **执行逻辑**:

  1. **合并**: 将两路检索返回的所有结果（最多 30 个）合并到一个列表中。
  2. **全局排序**: 根据每个知识片段的 `metadata.score` 字段（由检索器或 Reranker 生成的相关性分数），对所有结果进行**全局降序排序**。
  3. **重写索引**: 遍历排序后的列表，重写每个片段的 `metadata.position` 字段，使其从 1 开始连续递增。
- **价值**: 确保了无论知识片段来自哪个知识库、通过哪种方式检索，最终送入生成模型的都是**全局相关性最高**的 Top K 内容。

**步骤 6：答案生成（****`Generator`**  **- 回答生成）**

- **节点类型**: LLM
- **核心功能**: 接收经过智能排序后的、最高质量的知识库上下文，并生成最终答案。
- **提示词（Prompt）展示**:

```
**User Prompt:**

======================= 知识库内容 =======================

{{#context#}}

======================= 用户输入（已根据上下文改写） =======================
用户原始query：

{{#sys.query#}}

基于多轮对话优化的用户query：

{{#1755605354684.text#}}

你是一个顶级的 MindSpore 技术专家，你的核心任务是基于上方提供的知识库内容，尽最大努力为用户生成精准、纯粹的技术答案。

【核心回答原则】

- **知识库是第一信息源**：你的回答必须绝对优先、并尽可能全面地基于上方提供的“知识库内容”。
- **谨慎补充自有知识**：仅当知识库内容不足以回答问题时，才可动用你自身的 MindSpore 知识储备进行补充。

... (此处省略与“报错地图版”相似的QA优先、代码处理、禁止项等规则) ...

【回答生成策略】
你必须按以下优先级顺序来决定如何回答：

1. **基于知识库回答**：如果知识库内容**直接且充分**地回答了用户问题，请严格依据知识库内容进行回答。
2. **补充知识库回答**：如果知识库内容相关但**不完整**，请在知识库内容的基础上，结合你自身的MindSpore知识进行补充，形成一个全面的答案。
3. **基于自身知识回答**：如果知识库内容**完全不相关或缺失**，你**必须**利用自己全部的MindSpore知识储备，尽力提供一个最可能正确和有用的答案。**即使没有外部知识，也绝不放弃回答。**
```

**步骤 7：历史更新与输出（****`Assign2`** **,**  **`Answer`** **）**

- **`Assign2`** **（变量赋值 2）** : 将 `Generator` 生成的最终回答追加到 `conversation_history` 中，完成对话闭环。
- **`Answer`** **（结束）** : 将最终答案呈现给用户。

#### **5. 总结**

`昇思知识库 Workflow`是一个高度精密和智能的 RAG 工作流，其先进性体现在：

1. **引入 HyDE**: 通过生成假想答案，将检索从“关键词匹配”提升到了“深层语义理解”的维度。
2. **非对称双擎检索**: 针对不同类型的知识库（API vs 非API）采用不同的最优检索策略（语义优先 vs 混合+精排）。
3. **全局评分排序**: 摒弃了简单的结果拼接，通过对所有召回结果的`score`进行全局排序，实现了真正的“优中选优”。

# 遇到的问题及解决方案：

在“基于MindSpore代码助手系统”的开发过程中，我们主要围绕提升问答系统的准确性和用户体验，解决了一系列技术难题。以下是核心问题的总结及我们的解决方案与心得。

#### **1. 问题：混合查询场景下，检索准确率与召回率不佳**

- **问题描述：** 在项目初期，我们采用单一的向量检索（Vector Search）方案。该方案在处理语义相近的自然语言问句时表现尚可，但当用户查询包含精确的API名称、特定参数或错误码时，其检索效果急剧下降，经常无法召回最直接相关的文档，导致“答非所问”。
- **解决方案：**

  1. **多路召回与混合检索：**  我们摒弃了单一检索路径，设计并实现了“关键词检索 + 向量检索”的多路召回架构。关键词检索专门负责处理API、参数等专有名词的精确匹配，而向量检索则继续负责处理自然语言的语义理解。
  2. **分库检索策略：**  将知识库物理隔离为“API文档库”和“教程与FAQ库”。系统通过意图识别，将明确查询API的请求优先路由至API库，提高了检索的针对性。
  3. **引入Rerank模型：**  在多路召回之后，我们增加了一个Rerank（重排序）层。该模型会对所有召回的文档片段（Chunks）进行与原始问题相关性的二次精排，确保最相关的内容能够排在最前面，送入后续的生成模型。
- **总结与心得：** 对于技术型知识库问答，单一的检索模式存在明显短板。 **“先广后精”的检索策略是提升效果的关键**。通过多路召回扩大检索范围（保“全”），再利用Rerank模型进行精准排序（提“准”），最终形成了一个优势互补的检索闭环。实践证明，Rerank层的加入对最终答案质量的提升起到了决定性作用，是RAG管道中性价比极高的优化点。

#### **2. 问题：长对话中上下文信息丢失，导致指代不明**

- **问题描述：** 在多轮对话中，用户经常使用“它”、“有什么用”、“怎么解决”等指代性短语。初版系统无法理解这些指代的具体对象，导致后续回答逻辑混乱。例如，在询问 `mindspore.nn.Conv2d` 后再问“它支持哪些设备”，系统无法将“它”正确解析为 `Conv2d`。
- **解决方案：**

  1. **构建对话历史管理模块：**  在系统中缓存最近的N轮对话历史。
  2. **开发查询改写（Query Rewriting）模块：**  在检索之前，我们利用一个轻量级大语言模型（LLM）对用户当前输入进行改写。该模型的核心任务是结合对话历史，将用户的模糊、指代性问题，改写成一个独立的、包含完整上下文信息的“完美问题”（Perfect Query）。例如，将“它支持哪些设备”改写为“MindSpore的Conv2d算子支持哪些硬件设备”。
- **总结与心得：让检索系统“读懂”对话历史是实现流畅多轮交互的核心。**  与其让下游的检索和生成模块去被动适应不完整的用户输入，不如在流程的最开始，主动地、一次性地将问题“净化”和“补全”。查询改写模块如同一个“上下文翻译官”，它确保了无论RAG管道的后续环节多么复杂，其收到的输入始终是清晰、明确、无歧义的。这一设计理念极大地简化了后续模块的复杂度，并显著提升了多轮对话的连贯性。

#### **3. 问题：答案生成质量不稳定，易受知识库噪声干扰**

- **问题描述：** 尽管我们努力优化检索，但召回的知识库内容中仍可能包含部分不相关或过时的信息（噪声）。生成模型在处理这些带有噪声的上下文时，有时会产生事实错误、逻辑矛盾或“缝合痕迹”明显的答案。
- **解决方案：**

  1. **优化Prompt Engineering：**  我们设计了非常详尽和结构化的Prompt模板。通过角色扮演（“你是一个顶级的MindSpore技术专家”）、设定严格的回答规则（如“必须优先基于知识库”、“禁止提及信息来源”）、以及提供回答策略（优先顺序），来强力约束模型的行为，引导其更稳定地生成高质量答案。
  2. **答案生成与知识源分离：**  在Prompt中明确指示模型，严禁在回答中暴露“根据知识库”、“文档显示”等溯源信息，使用户看到的永远是直接、纯粹的技术答案，提升了答案的专业性和可信度。

- **总结与心得：对于RAG系统，生成环节的控制力同样重要。**  不能将优化希望完全寄托于检索的完美。一个精心设计的Prompt是给模型戴上的“紧箍咒”，它能在很大程度上弥补检索阶段的不足，是确保输出质量的最后一道坚固防线。通过不断迭代和优化Prompt，我们能够更精细地控制模型的回答风格、内容详略以及事实准确性，从而实现稳定、可靠的最终输出。

# **后续工作安排**

后续工作重心将转向实际部署与用户验证。我们计划立即将系统部署至线上服务器，并随之启动公开测试。